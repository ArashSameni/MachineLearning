{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character Recognition Using Single Layer Perceptron Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha: Learning Rate\n",
    "# theta: Threshold\n",
    "def linear_perceptron_network(inputs, targets, alpha = 1, theta = 0, max_iterations = 5000):\n",
    "    n = len(inputs[0])  # features count\n",
    "    m = len(targets[0]) # neurons count\n",
    "    epsilon = 1e-6\n",
    "    weights = np.zeros([m, n])\n",
    "    bias = np.zeros(m)\n",
    "    trained = False\n",
    "    epoch = 0\n",
    "    while epoch < max_iterations and not trained:\n",
    "        trained = True\n",
    "        for input, target in zip(inputs, targets):\n",
    "            h = weights.dot(input) + bias\n",
    "            h[h > theta] = 1\n",
    "            h[h < -theta] = -1\n",
    "            h[(h >= -theta) & (h <= theta)] = 0\n",
    "            \n",
    "            for j in range(m):\n",
    "                h_j = h[j]\n",
    "                t_j = target[j]\n",
    "                if abs(h_j - t_j) > epsilon:\n",
    "                    weights[j] = weights[j] + alpha * input * t_j\n",
    "                    bias[j] = bias[j] + alpha * t_j\n",
    "                    trained = False\n",
    "\n",
    "        epoch += 1\n",
    "    \n",
    "    return (trained, weights, bias, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 7 # width of letters\n",
    "h = 9 # height of letters\n",
    "letter_mapping = {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'j': 5, 'k': 6} # for each character which neuron should be active\n",
    "\n",
    "def read_file(file):\n",
    "    result = np.zeros((h, w))\n",
    "    lines = [line.rstrip('\\n') for line in open(file)]\n",
    "    for y, line in enumerate(lines):\n",
    "        for x, ch in enumerate(line):\n",
    "            result[y, x] = 1 if ch == '*' else -1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Result: True, Iterations: 6\n"
     ]
    }
   ],
   "source": [
    "def train_folder():\n",
    "    dir_path = './training_data/'\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.endswith('.txt'):\n",
    "            ch = file[0]\n",
    "            matrix = read_file(dir_path + file)\n",
    "            matrix = matrix.reshape(w * h) # change to one dimension\n",
    "            inputs.append(matrix)\n",
    "\n",
    "            # target array represents activation of neurons (1: active, -1: inactive)\n",
    "            # all neurons should be inactive(-1) except the neuron that represents the current input character\n",
    "            target = np.array([-1] * len(letter_mapping))\n",
    "            target[letter_mapping[ch]] = 1\n",
    "            targets.append(target)\n",
    "\n",
    "    return linear_perceptron_network(inputs, targets, 1)\n",
    "\n",
    "trained, weights, bias, epoch = train_folder()\n",
    "print(f'Training Result: {trained}, Iterations: {epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k1 = k\n",
      "k2 = k\n",
      "k3 = k\n",
      "j3 = j\n",
      "j2 = j\n",
      "j1 = j\n",
      "a1 = a\n",
      "a2 = a\n",
      "a3 = a\n",
      "c1 = c\n",
      "c3 = c\n",
      "c2 = c\n",
      "b2 = b\n",
      "b3 = b\n",
      "b1 = b\n",
      "e3 = e\n",
      "e2 = e\n",
      "e1 = e\n",
      "d1 = d\n",
      "d2 = d\n",
      "d3 = d\n",
      "\n",
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "def test(input):\n",
    "    theta = 0\n",
    "    guesses = {} # guesses of the network for current input\n",
    "    h = weights.dot(input) + bias # h is vector of neuron values\n",
    "    reverse_letter_mapping = {y: x for x, y in letter_mapping.items()}\n",
    "    for i in range(len(h)):\n",
    "        if h[i] > theta: # if h[i] > threshold, it means ith neuron is active\n",
    "            guesses[reverse_letter_mapping[i]] = h[i]\n",
    "    return guesses \n",
    "\n",
    "def test_folder():\n",
    "    text = ''\n",
    "    dir_path = './test_data/'\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    for file in os.listdir(dir_path):\n",
    "        if file.endswith('.txt'):\n",
    "            ch = file[0]\n",
    "            matrix = read_file(dir_path + file)\n",
    "            matrix = matrix.reshape(w * h) # change to one dimension\n",
    "            guesses = test(matrix)\n",
    "            \n",
    "            text += '%s = %s\\n' %(file[:-len('.txt')], ', '.join(guesses))\n",
    "            total += 1\n",
    "            # check if the highest guess is the correct character\n",
    "            if len(guesses) > 0 and ch == max(guesses, key=guesses.get):\n",
    "                corrects += 1\n",
    "    print(text)\n",
    "    print(f'Accuracy: {corrects * 100 / total}%')\n",
    "\n",
    "test_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise:  5%, Accuracy: 100.00%\n",
      "Noise: 10%, Accuracy: 95.24%\n",
      "Noise: 20%, Accuracy: 95.24%\n",
      "Noise: 30%, Accuracy: 85.71%\n",
      "Noise: 50%, Accuracy: 61.90%\n"
     ]
    }
   ],
   "source": [
    "def make_noisy_input(input, percent):\n",
    "    x = input.copy()\n",
    "    num_mistake = math.ceil(percent * w * h / 100)\n",
    "    for _ in range(num_mistake):\n",
    "        index = random.randint(0, w * h - 1)\n",
    "        x[index] = x[index] * -1\n",
    "        \n",
    "    return x\n",
    "\n",
    "def test_noisy():\n",
    "    dir_path = './training_data/'\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    noise_percents = [5, 10, 20, 30, 50]\n",
    "    for noise in noise_percents:\n",
    "        for file in os.listdir(dir_path):\n",
    "            if file.endswith('.txt'):\n",
    "                ch = file[0]\n",
    "                matrix = read_file(dir_path + file).reshape(w * h)\n",
    "                matrix = make_noisy_input(matrix, noise)\n",
    "                guesses = test(matrix)\n",
    "                \n",
    "                total += 1\n",
    "                # check if the highest guess is the correct character\n",
    "                if len(guesses) > 0 and ch == max(guesses, key=guesses.get):\n",
    "                    corrects += 1\n",
    "\n",
    "        print(f'Noise: {noise:2}%, Accuracy: {corrects * 100 / total:.2f}%')\n",
    "        \n",
    "        corrects = 0\n",
    "        total = 0\n",
    "\n",
    "test_noisy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
